"""
Dash ì•± ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
ëª¨ë¸ ìŠ¤ìº”, ì„¤ì • ê´€ë¦¬ ë“±
"""

import os
import json
import time
import shutil
from typing import List, Dict, Any, Optional
from src.utils.logger import get_logger

# ë¡œê±° ì„¤ì •
logger = get_logger("dash_utils")


def get_model_metadata(model_path: str) -> Optional[Dict[str, Any]]:
    """ëª¨ë¸ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤."""
    try:
        # JSON ë©”íƒ€ë°ì´í„° íŒŒì¼ í™•ì¸
        metadata_file = os.path.join(model_path, "metadata_last.json")
        if os.path.exists(metadata_file):
            with open(metadata_file, "r", encoding="utf-8") as f:
                metadata = json.load(f)
                return {
                    "episode": metadata.get("episode", 0),
                    "date": time.strftime(
                        "%m-%d %H:%M", time.localtime(metadata.get("save_time", 0))
                    ),
                    "full_metadata": metadata,
                }

        # PyTorch ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë©”íƒ€ë°ì´í„° í™•ì¸
        checkpoint_file = os.path.join(model_path, "checkpoint_last.pth")
        if os.path.exists(checkpoint_file):
            try:
                import torch

                # PyTorch 2.6 í˜¸í™˜ì„±ì„ ìœ„í•´ weights_only=False ëª…ì‹œì  ì„¤ì •
                checkpoint = torch.load(
                    checkpoint_file, map_location="cpu", weights_only=False
                )
                if (
                    "training_metadata" in checkpoint
                    and checkpoint["training_metadata"]
                ):
                    metadata = checkpoint["training_metadata"]
                    episode = checkpoint.get(
                        "episode", metadata.get("current_episode", 0)
                    )
                    save_time = checkpoint.get("save_time", time.time())
                    return {
                        "episode": episode,
                        "date": time.strftime("%m-%d %H:%M", time.localtime(save_time)),
                        "full_metadata": metadata,
                    }
            except Exception as e:
                logger.debug(f"PyTorch ì²´í¬í¬ì¸íŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")

        return None
    except Exception as e:
        logger.debug(f"ë©”íƒ€ë°ì´í„° ì½ê¸° ì‹¤íŒ¨ ({model_path}): {e}")
        return None


def load_model_training_config(model_path: str) -> Optional[Dict[str, Any]]:
    """ëª¨ë¸ì˜ í•™ìŠµ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    metadata = get_model_metadata(model_path)
    if metadata and "full_metadata" in metadata:
        return metadata["full_metadata"].get("training_config", {})
    return None


def get_latest_episode_from_model(model_path: str) -> int:
    """ëª¨ë¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤ì œë¡œ ì €ì¥ëœ ìµœì‹  ì—í”¼ì†Œë“œ ë²ˆí˜¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        # ë¨¼ì € ë©”íƒ€ë°ì´í„°ì—ì„œ í™•ì¸
        metadata_info = get_model_metadata(model_path)
        if metadata_info and metadata_info.get("episode", 0) > 0:
            return metadata_info["episode"]

        # ë©”íƒ€ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì—í”¼ì†Œë“œê°€ 0ì¸ ê²½ìš°, ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì§ì ‘ ìŠ¤ìº”
        if os.path.exists(model_path):
            checkpoint_files = []
            for file in os.listdir(model_path):
                if (
                    file.startswith("checkpoint_")
                    and file.endswith(".pth")
                    and "last" not in file
                ):
                    try:
                        # checkpoint_0001.pth í˜•ì‹ì—ì„œ ìˆ«ì ì¶”ì¶œ
                        episode_str = file.replace("checkpoint_", "").replace(
                            ".pth", ""
                        )
                        episode_num = int(episode_str)
                        checkpoint_files.append(episode_num)
                    except ValueError:
                        continue

            if checkpoint_files:
                latest_episode = max(checkpoint_files)
                logger.info(
                    f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ìŠ¤ìº”ìœ¼ë¡œ ìµœì‹  ì—í”¼ì†Œë“œ ë°œê²¬: {latest_episode}"
                )
                return latest_episode

        logger.warning(f"ëª¨ë¸ {model_path}ì—ì„œ ìœ íš¨í•œ ì—í”¼ì†Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return 0

    except Exception as e:
        logger.error(f"ìµœì‹  ì—í”¼ì†Œë“œ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ({model_path}): {e}")
        return 0


def get_available_models() -> List[Dict[str, str]]:
    """ë°±í…ŒìŠ¤íŒ…ì— ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜ (í•„ìˆ˜ íŒŒì¼ ì²´í¬ ë° ë¬´íš¨í•œ í´ë” ì‚­ì œ)"""
    model_options = []
    deleted_folders = []

    try:
        # ./model ë””ë ‰í† ë¦¬ í™•ì¸
        model_base_dir = "./model"
        if os.path.exists(model_base_dir):
            # rl_ddpgë¡œ ì‹œì‘í•˜ëŠ” ë””ë ‰í† ë¦¬ë“¤ ì°¾ê¸°
            for item in os.listdir(model_base_dir):
                item_path = os.path.join(model_base_dir, item)
                if os.path.isdir(item_path) and item.startswith("rl_ddpg"):

                    # ë°±í…ŒìŠ¤íŒ…ì— í•„ìš”í•œ í•„ìˆ˜ íŒŒì¼ë“¤ í™•ì¸
                    checkpoint_file = os.path.join(item_path, "checkpoint_last.pth")
                    metadata_file = os.path.join(item_path, "metadata_last.json")

                    # ë‘ íŒŒì¼ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                    if os.path.exists(checkpoint_file) and os.path.exists(
                        metadata_file
                    ):
                        # ë©”íƒ€ë°ì´í„° í™•ì¸
                        metadata_info = get_model_metadata(item_path)
                        if metadata_info:
                            label = f"ğŸ“ {item} (E{metadata_info['episode']}, {metadata_info['date']})"
                        else:
                            label = f"ğŸ“ {item}"

                        model_options.append({"label": label, "value": item_path})
                        logger.debug(f"âœ… ë°±í…ŒìŠ¤íŒ… ê°€ëŠ¥í•œ ëª¨ë¸ ë°œê²¬: {item_path}")
                    else:
                        # í•„ìˆ˜ íŒŒì¼ì´ ëˆ„ë½ëœ ê²½ìš° í´ë” ì‚­ì œ
                        missing_files = []
                        if not os.path.exists(checkpoint_file):
                            missing_files.append("checkpoint_last.pth")
                        if not os.path.exists(metadata_file):
                            missing_files.append("metadata_last.json")

                        # ê¸°ë³¸ ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì‚­ì œ (ì•ˆì „ì¥ì¹˜)
                        if item not in ["rl_ddpg", "rl_ddpg_latest"]:
                            try:
                                logger.info(
                                    f"ğŸ—‘ï¸ í•„ìˆ˜ íŒŒì¼ ëˆ„ë½ìœ¼ë¡œ ì¸í•œ ëª¨ë¸ í´ë” ì‚­ì œ: {item_path}"
                                )
                                logger.info(
                                    f"   ëˆ„ë½ëœ íŒŒì¼: {', '.join(missing_files)}"
                                )
                                shutil.rmtree(item_path)
                                deleted_folders.append(item)
                                logger.info(f"âœ… í´ë” ì‚­ì œ ì™„ë£Œ: {item}")
                            except Exception as e:
                                logger.error(f"âŒ í´ë” ì‚­ì œ ì‹¤íŒ¨ ({item}): {str(e)}")
                        else:
                            logger.debug(
                                f"âš ï¸ ê¸°ë³¸ ëª¨ë¸ {item}ì— í•„ìˆ˜ íŒŒì¼ ëˆ„ë½: {', '.join(missing_files)} (ì‚­ì œí•˜ì§€ ì•ŠìŒ)"
                            )

        # ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œë“¤ë„ ë™ì¼í•œ ì¡°ê±´ìœ¼ë¡œ í™•ì¸ (ì‚­ì œí•˜ì§€ ì•ŠìŒ)
        default_models = [
            {"label": "ğŸ¯ ê¸°ë³¸ DDPG ëª¨ë¸", "value": "./model/rl_ddpg"},
            {"label": "ğŸ“Š ìµœì‹  ì²´í¬í¬ì¸íŠ¸", "value": "./model/rl_ddpg_latest"},
        ]

        # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ê¸°ë³¸ ëª¨ë¸ë“¤ ì¶”ê°€ (í•„ìˆ˜ íŒŒì¼ ì²´í¬)
        existing_values = {opt["value"] for opt in model_options}
        for default_model in default_models:
            if default_model["value"] not in existing_values:
                # ê¸°ë³¸ ëª¨ë¸ë„ í•„ìˆ˜ íŒŒì¼ í™•ì¸
                checkpoint_file = os.path.join(
                    default_model["value"], "checkpoint_last.pth"
                )
                metadata_file = os.path.join(
                    default_model["value"], "metadata_last.json"
                )

                if os.path.exists(checkpoint_file) and os.path.exists(metadata_file):
                    metadata_info = get_model_metadata(default_model["value"])
                    if metadata_info:
                        default_model[
                            "label"
                        ] += f" (E{metadata_info['episode']}, {metadata_info['date']})"
                    model_options.insert(0, default_model)
                    logger.debug(f"âœ… ê¸°ë³¸ ëª¨ë¸ ì¶”ê°€: {default_model['value']}")

        # ì‚­ì œ ê²°ê³¼ ë¡œê¹…
        if deleted_folders:
            logger.info(
                f"ğŸ§¹ ì •ë¦¬ ì™„ë£Œ: {len(deleted_folders)}ê°œ ë¬´íš¨í•œ ëª¨ë¸ í´ë” ì‚­ì œë¨ ({', '.join(deleted_folders)})"
            )

        logger.info(f"ğŸ“Š ë°±í…ŒìŠ¤íŒ… ê°€ëŠ¥í•œ ëª¨ë¸ {len(model_options)}ê°œ ë°œê²¬")

    except Exception as e:
        logger.error(f"ëª¨ë¸ ë””ë ‰í† ë¦¬ ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜: {e}")
        model_options = []

    return (
        model_options
        if model_options
        else [{"label": "âŒ ë°±í…ŒìŠ¤íŒ… ê°€ëŠ¥í•œ ëª¨ë¸ ì—†ìŒ (í•„ìˆ˜ íŒŒì¼ ëˆ„ë½)", "value": ""}]
    )


# ğŸ¨ ìŠ¤íƒ€ì¼ ìƒìˆ˜ë“¤
CARD_STYLE = {
    "margin": "8px",
    "border-radius": "12px",
    "box-shadow": "0 2px 8px rgba(0, 0, 0, 0.1)",
    "border": "1px solid rgba(0, 0, 0, 0.05)",
}

METRIC_CARD_STYLE = {
    **CARD_STYLE,
    "text-align": "center",
    "height": "120px",
    "padding": "8px",
}

CUSTOM_CSS = {
    "font-family": "'Inter', sans-serif",
    "background": "linear-gradient(135deg, #667eea 0%, #764ba2 100%)",
    "min-height": "100vh",
}


def save_as_default_model(source_model_path: str) -> Dict[str, Any]:
    """ì„ íƒëœ ëª¨ë¸ì„ ê¸°ë³¸ DDPG ëª¨ë¸ë¡œ ì €ì¥"""
    try:
        # ê¸°ë³¸ ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        default_model_path = "./model/rl_ddpg"

        # ì†ŒìŠ¤ ëª¨ë¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(source_model_path):
            return {
                "success": False,
                "message": f"ì†ŒìŠ¤ ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {source_model_path}",
            }

        # í•„ìˆ˜ íŒŒì¼ë“¤ í™•ì¸
        required_files = ["checkpoint_last.pth", "metadata_last.json"]
        missing_files = []

        for file_name in required_files:
            file_path = os.path.join(source_model_path, file_name)
            if not os.path.exists(file_path):
                missing_files.append(file_name)

        if missing_files:
            return {
                "success": False,
                "message": f"í•„ìˆ˜ íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_files)}",
            }

        # ëŒ€ìƒ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(default_model_path, exist_ok=True)

        # ê¸°ì¡´ íŒŒì¼ë“¤ ë°±ì—… (ìˆëŠ” ê²½ìš°)
        backup_created = False
        if os.path.exists(os.path.join(default_model_path, "checkpoint_last.pth")):
            backup_path = f"{default_model_path}_backup_{int(time.time())}"
            shutil.copytree(default_model_path, backup_path)
            backup_created = True
            logger.info(f"ê¸°ì¡´ ëª¨ë¸ ë°±ì—… ìƒì„±: {backup_path}")

        # íŒŒì¼ë“¤ ë³µì‚¬
        copied_files = []
        for file_name in os.listdir(source_model_path):
            source_file = os.path.join(source_model_path, file_name)
            target_file = os.path.join(default_model_path, file_name)

            if os.path.isfile(source_file):
                shutil.copy2(source_file, target_file)
                copied_files.append(file_name)

        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ (ê¸°ë³¸ ëª¨ë¸ë¡œ ì €ì¥ë˜ì—ˆìŒì„ í‘œì‹œ)
        metadata_file = os.path.join(default_model_path, "metadata_last.json")
        if os.path.exists(metadata_file):
            try:
                with open(metadata_file, "r", encoding="utf-8") as f:
                    metadata = json.load(f)

                metadata.update(
                    {
                        "saved_as_default": True,
                        "original_source": source_model_path,
                        "default_save_time": time.time(),
                        "backup_created": backup_created,
                    }
                )

                with open(metadata_file, "w", encoding="utf-8") as f:
                    json.dump(metadata, f, indent=2, ensure_ascii=False)

            except Exception as e:
                logger.warning(f"ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

        return {
            "success": True,
            "message": f"ëª¨ë¸ì´ ê¸°ë³¸ DDPG ëª¨ë¸ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤",
            "source": source_model_path,
            "target": default_model_path,
            "copied_files": copied_files,
            "backup_created": backup_created,
        }

    except Exception as e:
        error_msg = f"ê¸°ë³¸ ëª¨ë¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return {"success": False, "message": error_msg}


def delete_model_folder(model_path: str) -> Dict[str, Any]:
    """ëª¨ë¸ í´ë”ë¥¼ ì•ˆì „í•˜ê²Œ ì‚­ì œ"""
    try:
        # ëª¨ë¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(model_path):
            return {
                "success": False,
                "message": f"ì‚­ì œí•  ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}",
            }

        # ëª¨ë¸ ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸ (ë³´ì•ˆ ì²´í¬)
        if not os.path.basename(model_path).startswith("rl_ddpg"):
            return {
                "success": False,
                "message": f"í—ˆìš©ë˜ì§€ ì•Šì€ ëª¨ë¸ í´ë”ì…ë‹ˆë‹¤: {model_path}",
            }

        # ê¸°ë³¸ ëª¨ë¸ ë³´í˜¸ (ì‚­ì œ ê¸ˆì§€)
        protected_models = [
            "./model/rl_ddpg",
            "./model/rl_ddpg_latest",
            "model/rl_ddpg",
            "model/rl_ddpg_latest",
        ]

        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
        absolute_model_path = os.path.abspath(model_path)
        for protected_path in protected_models:
            if os.path.abspath(protected_path) == absolute_model_path:
                return {
                    "success": False,
                    "message": f"ê¸°ë³¸ ëª¨ë¸ì€ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {os.path.basename(model_path)}",
                }

        # ë©”íƒ€ë°ì´í„° ì •ë³´ ìˆ˜ì§‘ (ì‚­ì œ ì „ ë¡œê¹…ìš©)
        metadata_info = get_model_metadata(model_path)
        model_name = os.path.basename(model_path)

        # ëª¨ë¸ í´ë” ë‚´ìš© í™•ì¸ ë° ë¡œê¹…
        folder_contents = []
        try:
            for item in os.listdir(model_path):
                item_path = os.path.join(model_path, item)
                if os.path.isfile(item_path):
                    file_size = os.path.getsize(item_path)
                    folder_contents.append(f"{item} ({file_size:,} bytes)")
                else:
                    folder_contents.append(f"{item}/ (í´ë”)")
        except Exception as e:
            logger.warning(f"í´ë” ë‚´ìš© í™•ì¸ ì‹¤íŒ¨: {e}")

        # ì‚­ì œ ì „ ìƒì„¸ ë¡œê¹…
        logger.info(f"ğŸ—‘ï¸ ëª¨ë¸ í´ë” ì‚­ì œ ì‹œì‘: {model_path}")
        if metadata_info:
            logger.info(
                f"   ğŸ“Š ë©”íƒ€ë°ì´í„°: ì—í”¼ì†Œë“œ {metadata_info['episode']}, ë‚ ì§œ {metadata_info['date']}"
            )
        if folder_contents:
            logger.info(
                f"   ğŸ“ í´ë” ë‚´ìš©: {', '.join(folder_contents[:5])}{'...' if len(folder_contents) > 5 else ''}"
            )

        # ì‹¤ì œ í´ë” ì‚­ì œ ì‹¤í–‰
        shutil.rmtree(model_path)

        success_msg = f"ëª¨ë¸ í´ë”ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤: {model_name}"
        if metadata_info:
            success_msg += f" (ì—í”¼ì†Œë“œ {metadata_info['episode']})"

        logger.info(f"âœ… ëª¨ë¸ í´ë” ì‚­ì œ ì™„ë£Œ: {model_path}")
        return {"success": True, "message": success_msg}

    except PermissionError:
        error_msg = f"í´ë” ì‚­ì œ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {model_path}"
        logger.error(error_msg)
        return {"success": False, "message": error_msg}
    except Exception as e:
        error_msg = f"ëª¨ë¸ í´ë” ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        return {"success": False, "message": error_msg}


def get_model_deletion_info(model_path: str) -> Dict[str, Any]:
    """ëª¨ë¸ ì‚­ì œ ì „ ìƒì„¸ ì •ë³´ ì œê³µ"""
    try:
        if not os.path.exists(model_path):
            return {"exists": False, "message": "ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"}

        # ê¸°ë³¸ ì •ë³´
        model_name = os.path.basename(model_path)
        metadata_info = get_model_metadata(model_path)

        # í´ë” í¬ê¸° ê³„ì‚°
        total_size = 0
        file_count = 0
        for root, dirs, files in os.walk(model_path):
            for file in files:
                file_path = os.path.join(root, file)
                try:
                    total_size += os.path.getsize(file_path)
                    file_count += 1
                except OSError:
                    pass

        # ë³´í˜¸ëœ ëª¨ë¸ì¸ì§€ í™•ì¸
        protected_models = [
            "./model/rl_ddpg",
            "./model/rl_ddpg_latest",
            "model/rl_ddpg",
            "model/rl_ddpg_latest",
        ]
        absolute_model_path = os.path.abspath(model_path)
        is_protected = any(
            os.path.abspath(p) == absolute_model_path for p in protected_models
        )

        return {
            "exists": True,
            "model_name": model_name,
            "model_path": model_path,
            "is_protected": is_protected,
            "metadata": metadata_info,
            "total_size": total_size,
            "file_count": file_count,
            "size_mb": round(total_size / (1024 * 1024), 2) if total_size > 0 else 0,
        }

    except Exception as e:
        logger.error(f"ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return {"exists": False, "message": f"ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"}
